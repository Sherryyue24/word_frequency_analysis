# Dataç›®å½•ç»“æ„è¯´æ˜

## ğŸ¯ è®¾è®¡ç†å¿µ

dataç›®å½•é‡‡ç”¨**ç»Ÿä¸€è¾“å…¥ç®¡ç†**çš„è®¾è®¡ç†å¿µï¼Œæ‰€æœ‰ç”¨æˆ·è¾“å…¥çš„æ–‡ä»¶ï¼ˆæ–‡æœ¬æ–‡ä»¶ã€è¯æ±‡è¡¨æ–‡ä»¶ç­‰ï¼‰éƒ½æŒ‰ç…§å¤„ç†çŠ¶æ€è¿›è¡Œåˆ†ç±»ç®¡ç†ï¼Œé€šè¿‡ç¨‹åºé€»è¾‘è€Œéç›®å½•ç»“æ„æ¥åŒºåˆ†æ–‡ä»¶ç±»å‹å’Œå¤„ç†æ–¹å¼ã€‚

## ğŸ—‚ï¸ ç›®å½•ç»“æ„

```
data/
â”œâ”€â”€ ğŸ“ files/               # ğŸ“‚ ç»Ÿä¸€æ–‡ä»¶ç®¡ç†
â”‚   â”œâ”€â”€ ğŸ“ new/             # ğŸ†• å¾…å¤„ç†æ–‡ä»¶ (æ–‡æœ¬+è¯æ±‡è¡¨)
â”‚   â”œâ”€â”€ ğŸ“ processed/       # âœ… å·²å¤„ç†æ–‡ä»¶å½’æ¡£
â”‚   â””â”€â”€ ğŸ“ samples/         # ğŸ§ª ç¤ºä¾‹æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ ğŸ“ databases/           # ğŸ—ƒï¸ æ•°æ®åº“é›†ä¸­å­˜å‚¨
â”‚   â””â”€â”€ ğŸ“„ unified.db       # ğŸŒŸ ç»Ÿä¸€æ•°æ®åº“ (ç°ä»£åŒ–æ¶æ„)
â”œâ”€â”€ ğŸ“ cache/              # ğŸ’¾ ä¸´æ—¶ç¼“å­˜ (ç©º)
â””â”€â”€ ğŸ“ exports/            # ğŸ“¤ å¯¼å‡ºç»“æœ (ç©º)
```

## ğŸ”„ ç»Ÿä¸€æ•°æ®æµ

```
ç”¨æˆ·è¾“å…¥ â†’ files/new/ â†’ [æ™ºèƒ½å¤„ç†å¼•æ“] â†’ databases/ â†’ files/processed/
                              â†“
                        æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼:
                        â€¢ æ–‡æœ¬æ–‡ä»¶ â†’ è¯é¢‘åˆ†æ â†’ unified.db (documents + words + occurrences)
                        â€¢ è¯æ±‡è¡¨ â†’ è¯æ±‡å¯¼å…¥ â†’ unified.db (wordlists + memberships)
```

## ğŸ“‹ ç›®å½•åŠŸèƒ½è¯¦è§£

### ğŸ“‚ files/ - ç»Ÿä¸€æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†

| ç›®å½• | åŠŸèƒ½ | åŒ…å«æ–‡ä»¶ç±»å‹ | å¤„ç†çŠ¶æ€ |
|------|------|-------------|----------|
| `new/` | å¾…å¤„ç†é˜Ÿåˆ— | ğŸ“š æ–‡æœ¬æ–‡ä»¶ + ğŸ“ è¯æ±‡è¡¨æ–‡ä»¶ | ğŸ”„ æœªå¤„ç† |
| `processed/` | å·²å¤„ç†å½’æ¡£ | ğŸ“š å·²åˆ†ææ–‡æœ¬ + ğŸ“ å·²å¯¼å…¥è¯æ±‡è¡¨ | âœ… å·²å®Œæˆ |
| `samples/` | æµ‹è¯•æ ·æœ¬ | ğŸ§ª ç¤ºä¾‹æ–‡ä»¶ | ğŸ”¬ æµ‹è¯•ç”¨ |

**å½“å‰files/new/å†…å®¹ç¤ºä¾‹ï¼š**
```
ğŸ“š æ–‡æœ¬æ–‡ä»¶:
- A to Z Mysteriesç³»åˆ—PDF (è‹±æ–‡å„¿ç«¥è¯»ç‰©)
- story.txt, story2.txt (æµ‹è¯•æ–‡æœ¬)

ğŸ“ è¯æ±‡è¡¨æ–‡ä»¶:
- IELTS_Word_List.txt (é›…æ€è¯æ±‡ 3,707è¯)
- GRE_8000_Words.txt (GREè¯æ±‡ 7,744è¯) 
- CET_4+6_edited.txt (å››å…­çº§è¯æ±‡ 8,028è¯)
- allWords.xlsx (ç»¼åˆè¯æ±‡è¡¨)
- æŸ¯æ—æ–¯è¯é¢‘-5æ˜Ÿè‡³0æ˜Ÿ.xlsx (è¯é¢‘æ•°æ®)
- è‹±è¯­ä¸“ä¸šå››å…«çº§è¯æ±‡è¡¨.docx (ä¸“ä¸šè¯æ±‡)
```

### ğŸ—ƒï¸ databases/ - ç»Ÿä¸€æ•°æ®åº“æ¶æ„

```
databases/
â””â”€â”€ unified.db      # ğŸŒŸ ç°ä»£åŒ–ç»Ÿä¸€æ•°æ®åº“ (UUID-based)
    â”œâ”€â”€ ğŸ“„ documents (æ–‡æ¡£ç®¡ç†)
    â”‚   â”œâ”€â”€ æ–‡æ¡£å…ƒæ•°æ® (filename, content_hash, file_size)
    â”‚   â”œâ”€â”€ å¤„ç†çŠ¶æ€ (status, processed_at)
    â”‚   â””â”€â”€ JSONå­—æ®µ (metadata, çµæ´»æ‰©å±•)
    â”œâ”€â”€ ğŸ”¤ words (ç»Ÿä¸€è¯æ±‡è¡¨)
    â”‚   â”œâ”€â”€ è¡¨é¢å½¢å¼ (surface_form: "running")
    â”‚   â”œâ”€â”€ è¯æ ¹å½¢å¼ (lemma: "run")
    â”‚   â””â”€â”€ è¯­è¨€å­¦ç‰¹å¾ (linguistic_features)
    â”œâ”€â”€ ğŸ“Š occurrences (è¯é¢‘å…³è”)
    â”‚   â”œâ”€â”€ æ–‡æ¡£-è¯æ±‡å…³è” (document_id + word_id)
    â”‚   â”œâ”€â”€ é¢‘ç‡ç»Ÿè®¡ (frequency, tf_score)
    â”‚   â””â”€â”€ ä½ç½®ä¿¡æ¯ (positions JSON)
    â”œâ”€â”€ ğŸ“š wordlists (è¯æ±‡è¡¨ç®¡ç†)
    â”‚   â”œâ”€â”€ è¯æ±‡è¡¨ä¿¡æ¯ (IELTS/GRE/CETç­‰)
    â”‚   â”œâ”€â”€ ç‰ˆæœ¬ç®¡ç† (version, source_file)
    â”‚   â””â”€â”€ ç»Ÿè®¡ä¿¡æ¯ (word_count)
    â””â”€â”€ ğŸ”— word_wordlist_memberships (å…³è”è¡¨)
        â”œâ”€â”€ è¯æ±‡-è¯æ±‡è¡¨å…³è”
        â”œâ”€â”€ ç½®ä¿¡åº¦è¯„åˆ† (confidence)
        â””â”€â”€ æ¥æºå…ƒæ•°æ® (source_metadata)
```

### ğŸ”§ å·¥å…·ç›®å½•

| ç›®å½• | ç”¨é€” | å½“å‰çŠ¶æ€ |
|------|------|----------|
| `cache/` | å¤„ç†è¿‡ç¨‹ä¸´æ—¶æ–‡ä»¶ | ç©º |
| `exports/` | å¯¼å‡ºç»“æœå­˜å‚¨ | ç©º |

## ğŸ¯ è®¾è®¡ä¼˜åŠ¿

### 1. **ç»Ÿä¸€è¾“å…¥ç®¡ç†**
- æ‰€æœ‰è¾“å…¥æ–‡ä»¶éƒ½è¿›å…¥ `files/new/`
- ç¨‹åºæ™ºèƒ½è¯†åˆ«æ–‡ä»¶ç±»å‹å¹¶é€‰æ‹©å¤„ç†æ–¹å¼
- å¤„ç†å®Œæˆåç»Ÿä¸€å½’æ¡£åˆ° `files/processed/`

### 2. **æ¸…æ™°çš„çŠ¶æ€ç®¡ç†**
```
è¾“å…¥é˜¶æ®µ â†’ å¤„ç†é˜¶æ®µ â†’ å­˜å‚¨é˜¶æ®µ â†’ å½’æ¡£é˜¶æ®µ
new/      ç¨‹åºå¤„ç†    databases/   processed/
```

### 3. **ç®€åŒ–çš„ç›®å½•ç»“æ„**
- å‡å°‘ç›®å½•å±‚çº§ï¼Œé¿å…åŠŸèƒ½é‡å¤
- é€šè¿‡ä»£ç é€»è¾‘è€Œéç›®å½•åŒºåˆ†æ–‡ä»¶ç±»å‹
- æ›´å®¹æ˜“ç†è§£å’Œç»´æŠ¤

### 4. **çµæ´»çš„å¤„ç†æ–¹å¼**
```python
# æ™ºèƒ½æ–‡ä»¶å¤„ç†ä¼ªä»£ç 
for file in files/new/:
    if is_vocabulary_file(file):
        import_to_vocabulary_db(file)
    elif is_text_file(file):
        analyze_and_store(file)
    
    # å¤„ç†å®Œæˆåç§»åŠ¨åˆ°processed/
    move_to_processed(file)
```

## ğŸ’¡ ä½¿ç”¨åœºæ™¯

### ğŸ“ å¤„ç†è¯æ±‡è¡¨
```bash
# 1. æ”¾å…¥è¯æ±‡è¡¨æ–‡ä»¶
cp my_wordlist.txt data/files/new/

# 2. è¿è¡Œè¯æ±‡å¯¼å…¥
python run.py vocab import-words data/files/new/my_wordlist.txt

# 3. æ–‡ä»¶è‡ªåŠ¨å½’æ¡£åˆ°processed/
```

### ğŸ“š åˆ†ææ–‡æœ¬
```bash  
# 1. æ”¾å…¥æ–‡æœ¬æ–‡ä»¶
cp my_document.pdf data/files/new/

# 2. è¿è¡Œæ–‡æœ¬åˆ†æ
python run.py text process -i data/files/new/

# 3. æ–‡ä»¶è‡ªåŠ¨å½’æ¡£åˆ°processed/
```

## ğŸ”® æ‰©å±•æ€§

è¿™ç§è®¾è®¡æ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•ï¼š
- **æ–°æ–‡ä»¶ç±»å‹** - åªéœ€æ·»åŠ è¯†åˆ«å’Œå¤„ç†é€»è¾‘
- **æ‰¹é‡å¤„ç†** - å¯ä»¥æ‰¹é‡å¤„ç†new/ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶
- **å¤„ç†å†å²** - processed/ç›®å½•ä¿ç•™å®Œæ•´å¤„ç†å†å²
- **å·¥ä½œæµè‡ªåŠ¨åŒ–** - å¯ä»¥å®ç°ç›‘æ§new/ç›®å½•çš„è‡ªåŠ¨å¤„ç†

## ğŸ‰ æ€»ç»“

è¿™ç§**ç»Ÿä¸€è¾“å…¥ã€æ™ºèƒ½å¤„ç†ã€åˆ†ç±»å­˜å‚¨**çš„è®¾è®¡æ›´åŠ ç®€æ´å’Œé«˜æ•ˆï¼š
- ç”¨æˆ·åªéœ€å…³å¿ƒä¸€ä¸ªå…¥å£ï¼š`files/new/`
- ç³»ç»Ÿæ™ºèƒ½å¤„ç†ä¸åŒç±»å‹æ–‡ä»¶
- ç»“æœå­˜å‚¨åœ¨ç›¸åº”æ•°æ®åº“ä¸­
- åŸæ–‡ä»¶å½’æ¡£ä¾¿äºè¿½æº¯

è¿™æ˜¯ä¸€ä¸ªæ›´ç¬¦åˆç”¨æˆ·ç›´è§‰çš„è®¾è®¡ï¼

---

## ğŸ”— ä¸Enginesæ¨¡å—çš„åä½œ

### ä¸‰å±‚æ¶æ„é…åˆ

dataç›®å½•ç»“æ„ä¸æ ¸å¿ƒenginesæ¨¡å—çš„**ä¸‰å±‚æ¶æ„**ç´§å¯†é…åˆï¼š

```
ğŸ”½ Inputå±‚ (core/engines/input/)
    â†“ å¤„ç† files/new/ ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    â”œâ”€â”€ file_processor.py      â†’ æ–‡æœ¬æ–‡ä»¶æ‰¹é‡å¤„ç†
    â”œâ”€â”€ file_reader.py         â†’ å¤šæ ¼å¼æ–‡ä»¶è¯»å–  
    â””â”€â”€ modern_wordlist_import.py â†’ è¯æ±‡è¡¨æ–‡ä»¶å¯¼å…¥

ğŸ”„ Vocabularyå±‚ (core/engines/vocabulary/)
    â†“ å¯¹æ–‡æœ¬è¿›è¡Œè¯æ±‡åˆ†æ
    â””â”€â”€ word_analyzer.py       â†’ è¯é¢‘ç»Ÿè®¡ã€è¯­è¨€å­¦å¤„ç†

ğŸ’¾ Databaseå±‚ (core/engines/database/)
    â†“ å­˜å‚¨åˆ° databases/unified.db
    â”œâ”€â”€ unified_database.py    â†’ ç°ä»£åŒ–æ•°æ®åº“æ“ä½œ
    â””â”€â”€ database_adapter.py    â†’ å‘åå…¼å®¹æ¥å£
```

### æ•°æ®å¤„ç†æµç¨‹

#### æ–‡æœ¬æ–‡ä»¶å¤„ç†æµç¨‹
```
1. ç”¨æˆ·æ–‡ä»¶ â†’ data/files/new/document.pdf
2. Inputå±‚è¯»å– â†’ file_reader.py è§£æPDF
3. Vocabularyå±‚åˆ†æ â†’ word_analyzer.py æå–è¯é¢‘
4. Databaseå±‚å­˜å‚¨ â†’ unified_database.py ä¿å­˜åˆ°unified.db
5. æ–‡ä»¶å½’æ¡£ â†’ data/files/processed/document.pdf
```

#### è¯æ±‡è¡¨å¯¼å…¥æµç¨‹
```
1. è¯æ±‡è¡¨æ–‡ä»¶ â†’ data/files/new/IELTS_words.txt
2. Inputå±‚å¯¼å…¥ â†’ modern_wordlist_import.py è§£æè¯æ±‡
3. Databaseå±‚å­˜å‚¨ â†’ åˆ›å»ºwordlistè®°å½•å’Œwordå…³è”
4. æ–‡ä»¶å½’æ¡£ â†’ data/files/processed/IELTS_words.txt
```

### æ¨¡å—èŒè´£åˆ†å·¥

| å±‚çº§ | è´Ÿè´£çš„dataæ“ä½œ | å…·ä½“åŠŸèƒ½ |
|------|---------------|----------|
| **Inputå±‚** | `files/new/` â†’ `files/processed/` | æ–‡ä»¶è¯»å–ã€æ ¼å¼è½¬æ¢ã€çŠ¶æ€ç®¡ç† |
| **Vocabularyå±‚** | å†…å­˜ä¸­è¯æ±‡å¤„ç† | è¯æ±‡æå–ã€é¢‘ç‡è®¡ç®—ã€è¯­è¨€å­¦åˆ†æ |
| **Databaseå±‚** | `databases/unified.db` | æ•°æ®æŒä¹…åŒ–ã€å…³è”æŸ¥è¯¢ã€ç»Ÿè®¡åˆ†æ |

### é…ç½®é›†æˆ

enginesæ¨¡å—é€šè¿‡é…ç½®ç³»ç»Ÿä¸dataç›®å½•åä½œï¼š

```yaml
# config/default.yaml
database:
  path: "data/databases/unified.db"

processing:
  input_directory: "data/files/new"
  processed_directory: "data/files/processed"
  supported_formats: ["pdf", "txt", "docx", "xlsx"]

export:
  output_directory: "data/exports"
```

### é”™è¯¯æ¢å¤æœºåˆ¶

- **å¤„ç†å¤±è´¥çš„æ–‡ä»¶**: ä¿ç•™åœ¨ `files/new/` ç­‰å¾…é‡è¯•
- **æ•°æ®åº“äº‹åŠ¡**: ä½¿ç”¨SQLiteäº‹åŠ¡ä¿è¯æ•°æ®ä¸€è‡´æ€§
- **å¤‡ä»½æœºåˆ¶**: `databases/backup/` ä¿å­˜å†å²ç‰ˆæœ¬
- **æ—¥å¿—è®°å½•**: è¯¦ç»†è®°å½•å¤„ç†è¿‡ç¨‹å’Œé”™è¯¯ä¿¡æ¯

### æ€§èƒ½ä¼˜åŒ–

#### ç¼“å­˜ç­–ç•¥
```
data/cache/
â”œâ”€â”€ content_hashes/    # æ–‡ä»¶å†…å®¹å“ˆå¸Œç¼“å­˜
â”œâ”€â”€ word_frequencies/  # è¯é¢‘è®¡ç®—ç¼“å­˜  
â””â”€â”€ analysis_results/  # åˆ†æç»“æœç¼“å­˜
```

#### æ‰¹é‡å¤„ç†
```python
# enginesæ¨¡å—æ”¯æŒæ‰¹é‡å¤„ç†dataç›®å½•
from core.engines.input import FileProcessor

processor = FileProcessor()
processor.process_new_texts("data/files/new")  # æ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡ä»¶
```

### æ‰©å±•æ€§æ”¯æŒ

è¿™ç§æ¶æ„æ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•ï¼š

1. **æ–°è¾“å…¥æ ¼å¼**: åœ¨Inputå±‚æ·»åŠ æ–°çš„readeræ”¯æŒ
2. **é«˜çº§åˆ†æ**: åœ¨Vocabularyå±‚æ·»åŠ MLç®—æ³•
3. **å¤šæ•°æ®åº“**: Databaseå±‚æ”¯æŒåˆ†å¸ƒå¼å­˜å‚¨
4. **å®æ—¶ç›‘æ§**: ç›‘æ§ `files/new/` ç›®å½•è‡ªåŠ¨å¤„ç†æ–°æ–‡ä»¶

### æœ€ä½³å®è·µ

#### å¼€å‘æ–°åŠŸèƒ½æ—¶
```python
# 1. Inputå±‚å¤„ç† - æ·»åŠ æ–°æ ¼å¼æ”¯æŒ
def read_new_format(file_path):
    # è¯»å–æ–°æ ¼å¼æ–‡ä»¶
    return content

# 2. Vocabularyå±‚åˆ†æ - æ·»åŠ æ–°åˆ†æåŠŸèƒ½  
def advanced_analysis(text):
    # é«˜çº§è¯æ±‡åˆ†æ
    return analysis_result

# 3. Databaseå±‚å­˜å‚¨ - æ‰©å±•æ•°æ®æ¨¡å‹
def store_advanced_result(analysis):
    # å­˜å‚¨é«˜çº§åˆ†æç»“æœ
    pass
```

è¿™ç§**ä¸‰å±‚æ¶æ„ + ç»Ÿä¸€æ•°æ®ç®¡ç†**çš„è®¾è®¡å®ç°äº†ï¼š
- ğŸ“ æ¸…æ™°çš„æ•°æ®æµå‘
- ğŸ”§ æ¨¡å—åŒ–çš„åŠŸèƒ½åˆ†ç¦»  
- ğŸš€ å¼ºå¤§çš„æ‰©å±•èƒ½åŠ›
- ğŸ›¡ï¸ å¯é çš„é”™è¯¯å¤„ç†

ä¸ºç³»ç»Ÿçš„é•¿æœŸå‘å±•å¥ å®šäº†åšå®åŸºç¡€ï¼ 